## 架构设计与讨论

### 爬虫数据存储解析逻辑

- 爬虫数据
  - 保存成zip包，备份（清理策略）
  - 调解析接口（post）
- 解析
  - 跑爬虫数据解析任务（接收post参数解析）
  - 解析重跑逻辑（数据源？zip包）
  - 原始数据
- 报告
  - 接收中控跑报告任务
  - 拉取原始数据处理
  - 处理完成回调中控



### [Hive分析](https://cwiki.apache.org/confluence/display/Hive/LanguageManual)

- 作为数据仓库
  - 提供数据存储：
    - load数据从文件、HDFS
    - 查询结果插入Hive或文件系统
    - 利用SQL插入值到Hive表
  - 批处理不可变的大数据集
  - 不支持行级更新删除操作
    - 现在应该可以支持，但不推荐使用：需要Hive Transactions支持[ACID](https://cwiki.apache.org/confluence/display/Hive/Hive+Transactions)
  - 支持各种表关联操作
- 作为查询引擎(OLAP)

```sql
// Insert value Demo
CREATE TABLE students (name VARCHAR(64), age INT, gpa DECIMAL(3, 2))
  CLUSTERED BY (age) INTO 2 BUCKETS STORED AS ORC;
  
INSERT INTO TABLE students
  VALUES ('fred flintstone', 35, 1.28), ('barney rubble', 32, 2.32);
  
// 根据时间分区(探索原理)  
CREATE TABLE pageviews (userid VARCHAR(64), link STRING, came_from STRING)
  PARTITIONED BY (datestamp STRING) CLUSTERED BY (userid) INTO 256 BUCKETS STORED AS ORC;
 
INSERT INTO TABLE pageviews PARTITION (datestamp = '2014-09-23')
  VALUES ('jsmith', 'mail.com', 'sports.com'), ('jdoe', 'mail.com', null);
 
INSERT INTO TABLE pageviews PARTITION (datestamp)
  VALUES ('tjohnson', 'sports.com', 'finance.com', '2014-09-23'), ('tlee', 'finance.com', null, '2014-09-21');
  
INSERT INTO TABLE pageviews
  VALUES ('tjohnson', 'sports.com', 'finance.com', '2014-09-23'), ('tlee', 'finance.com', null, '2014-09-21');  
```



### HBase

支持十亿级别的大数据实时高性能读写(基于Key-Value)

支持上亿列、上百万行的

保证原子性

LSM树：存储算法；利用Memstore排序数据后，再存入HFile（尽量保证数据是顺序存储到磁盘）；是对B+tree的改进

压缩元数据(rowkey、column family、cq)：压缩与解压也是消耗性能的，根据数据的使用需求选择(读写场景)



> 不支持表关联
>
> ​	曲线救国：
>
> 1. 在存入HBase前，进行关联
> 2. 在MapReduce中进行关联



> 不适用场景：
>
> - 不适合数据分析场景
> - 单表数据量不超过千万不建议用



> 使用场景：
>
> - 单表数据量超千万，而且并发高
> - 数据分析需求弱，或不需要那么灵活或实时





### 搜索引擎

需要反向索引的场景



### 爬虫数据存储讨论

> * Hive
>
>   只存储数据：Insert语法
>
>   研究Hive的分区Partition实现方式，根据时间分区，后期历史数据可根据分区删除



### 报告数据存储

> - HBase



### 日志数据存储讨论

ES

HBase

